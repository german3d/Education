{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-tagging task\n",
    "\n",
    "Three models are used: <br>\n",
    "1) HMM <br>\n",
    "2) Naive Bayes Classifier (with generated features)<br>\n",
    "3) CRF (with generated features) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import brown\n",
    "from nltk.tag import hmm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Brown news corpora and splitting into train/test (80/20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train sentences: 3,698\n",
      "Number of test sentences: 925\n"
     ]
    }
   ],
   "source": [
    "corpora = brown.tagged_sents(categories=\"news\", tagset=\"universal\")\n",
    "corpora_train, corpora_test = train_test_split(corpora, test_size=0.2, random_state=13, shuffle=True)\n",
    "\n",
    "print(\"Number of train sentences: {:,}\".format(len(corpora_train)))\n",
    "print(\"Number of test sentences: {:,}\".format(len(corpora_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Markov Model (HMM) shows poor F1-score on test set. <br> \n",
    "We do not use any features here besides only knowledge of hidden states (POS-tags) and observed states (words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .       1.00      0.31      0.47      2396\n",
      "        ADJ       0.94      0.33      0.49      1303\n",
      "        ADP       0.94      0.39      0.55      2550\n",
      "        ADV       0.91      0.44      0.59       680\n",
      "       CONJ       1.00      0.36      0.53       522\n",
      "        DET       1.00      0.47      0.64      2303\n",
      "       NOUN       0.98      0.35      0.51      6180\n",
      "        NUM       1.00      0.37      0.54       442\n",
      "       PRON       0.04      0.99      0.08       517\n",
      "        PRT       0.95      0.40      0.56       470\n",
      "       VERB       0.99      0.45      0.62      2943\n",
      "          X       1.00      0.23      0.38        13\n",
      "\n",
      "avg / total       0.95      0.40      0.53     20319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer_hmm = hmm.HiddenMarkovModelTrainer()\n",
    "tagger_hmm = trainer_hmm.train_supervised(corpora_train)\n",
    "\n",
    "X_test = [nltk.tag.untag(sent) for sent in corpora_test] # List of sentences\n",
    "y_test = [word[1] for sent in corpora_test for word in sent] # Flatten list of POS\n",
    "\n",
    "# Hidden Markov model predictions\n",
    "y_hmm = [word[1] for sent in tagger_hmm.tag_sents(X_test) for word in sent] # Flatten list of POS\n",
    "print(classification_report(y_test, y_hmm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM with stemmed words performs substantially better. <br>\n",
    "The problem was described previously here - [link](https://github.com/nltk/nltk/issues/1095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .       1.00      0.47      0.64      2396\n",
      "        ADJ       0.84      0.44      0.58      1303\n",
      "        ADP       0.95      0.58      0.72      2550\n",
      "        ADV       0.86      0.57      0.69       680\n",
      "       CONJ       1.00      0.51      0.68       522\n",
      "        DET       0.99      0.63      0.77      2303\n",
      "       NOUN       0.92      0.49      0.64      6180\n",
      "        NUM       1.00      0.52      0.69       442\n",
      "       PRON       0.06      0.98      0.11       517\n",
      "        PRT       0.94      0.59      0.73       470\n",
      "       VERB       0.93      0.59      0.72      2943\n",
      "          X       1.00      0.46      0.63        13\n",
      "\n",
      "avg / total       0.92      0.55      0.67     20319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "corpora_train_stem = [[(porter.stem(word), tag) for word, tag in sent] for sent in corpora_train]\n",
    "corpora_test_stem = [[(porter.stem(word), tag) for word, tag in sent] for sent in corpora_test]\n",
    "\n",
    "trainer_hmm_stem = hmm.HiddenMarkovModelTrainer()\n",
    "tagger_hmm_stem = trainer_hmm_stem.train_supervised(corpora_train_stem)\n",
    "\n",
    "X_test_stem = [nltk.tag.untag(sent) for sent in corpora_test_stem]\n",
    "y_test_stem = [word[1] for sent in corpora_test_stem for word in sent]\n",
    "\n",
    "y_hmm_stem = [word[1] for sent in tagger_hmm_stem.tag_sents(X_test_stem) for word in sent]\n",
    "print(classification_report(y_test, y_hmm_stem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit Naive Bayes Classifier which uses generated features (both from current word and near context):\n",
    "- previous / current / next word and stem\n",
    "- suffix / prefix of current word\n",
    "- information about capital letters and numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'stem': porter.stem(sentence[index]),\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '<START>' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '<END>' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'prev_stem': '<START>' if index == 0 else porter.stem(sentence[index - 1]),\n",
    "        'next_stem': '<END>' if index == len(sentence) - 1 else porter.stem(sentence[index + 1]),\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:],        \n",
    "    }\n",
    "\n",
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i)\n",
    "                train_set.append((featureset, tag))\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        tags = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            tags.append(tag)\n",
    "        return zip(sentence, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Naive Bayes is the simple model which uses very basic features in this example, it demonstrates significantly better performance in comparison with plain HMM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .       1.00      1.00      1.00      2396\n",
      "        ADJ       0.80      0.89      0.84      1303\n",
      "        ADP       0.97      0.90      0.93      2550\n",
      "        ADV       0.81      0.86      0.84       680\n",
      "       CONJ       0.99      0.99      0.99       522\n",
      "        DET       1.00      0.99      0.99      2303\n",
      "       NOUN       0.97      0.91      0.94      6180\n",
      "        NUM       0.87      1.00      0.93       442\n",
      "       PRON       0.94      0.97      0.96       517\n",
      "        PRT       0.70      0.94      0.80       470\n",
      "       VERB       0.93      0.96      0.94      2943\n",
      "          X       0.16      0.77      0.27        13\n",
      "\n",
      "avg / total       0.95      0.94      0.94     20319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagger_nb = ConsecutivePosTagger(corpora_train)\n",
    "y_nb = [word[1] for sent in tagger_nb.tag_sents(X_test) for word in sent]\n",
    "\n",
    "print(classification_report(y_test, y_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use CRF algorithm (*pycrfsuit* module) and try to improve our previous results. <br>\n",
    "Let's slightly rewrite previous code, but not changing core function which generates dictionary of features for each word in sentence. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRFPosTagger:\n",
    "    def __init__(self):\n",
    "        self.trainer = pycrfsuite.Trainer(verbose=False)\n",
    "        \n",
    "    def prepare_features(self, corpora):\n",
    "        X, y = [], []\n",
    "        for tagged_sent in corpora:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            X_sent, y_sent = [], []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i)\n",
    "                X_sent.append(featureset)\n",
    "                y_sent.append(tag)\n",
    "            X.append(X_sent)\n",
    "            y.append(y_sent)\n",
    "        return X, y\n",
    "    \n",
    "    def train(self, corpora_train, **params):\n",
    "        X_train, y_train = self.prepare_features(corpora_train)\n",
    "        for xseq, yseq in zip(X_train, y_train):\n",
    "            self.trainer.append(pycrfsuite.ItemSequence(xseq), yseq)\n",
    "        self.trainer.set_params({\n",
    "                'c1': 1.0,\n",
    "                'c2': 1e-3,\n",
    "                'max_iterations': 50,\n",
    "                'feature.possible_transitions': True\n",
    "        })\n",
    "        self.trainer.set_params(params)\n",
    "        self.trainer.train(model=\"trainer.pycrfsuit\");\n",
    "        self.tagger = pycrfsuite.Tagger();\n",
    "        self.tagger.open(\"trainer.pycrfsuit\");\n",
    "    \n",
    "    def test(self, corpora_test):\n",
    "        X_test, y_test = self.prepare_features(corpora_test)\n",
    "        return [self.tagger.tag(pycrfsuite.ItemSequence(xseq)) for xseq in X_test]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude, that CRF outperforms Naive Bayes classifier (both use the same featureset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .       1.00      1.00      1.00      2396\n",
      "        ADJ       0.90      0.86      0.88      1303\n",
      "        ADP       0.97      0.98      0.98      2550\n",
      "        ADV       0.94      0.88      0.91       680\n",
      "       CONJ       1.00      1.00      1.00       522\n",
      "        DET       1.00      0.99      0.99      2303\n",
      "       NOUN       0.96      0.98      0.97      6180\n",
      "        NUM       1.00      0.99      0.99       442\n",
      "       PRON       0.98      0.98      0.98       517\n",
      "        PRT       0.94      0.93      0.94       470\n",
      "       VERB       0.97      0.96      0.96      2943\n",
      "          X       0.62      0.62      0.62        13\n",
      "\n",
      "avg / total       0.97      0.97      0.97     20319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagger_crf = CRFPosTagger()\n",
    "tagger_crf.train(corpora_train)\n",
    "\n",
    "y_crf = [word for sent in tagger_crf.test(corpora_test) for word in sent]\n",
    "\n",
    "print(classification_report(y_test, y_crf))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
